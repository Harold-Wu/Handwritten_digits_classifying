#########################################
#v0.0.1: Q1, 2, 3a, 4.  *WH*
#V0.0.2: Q1 revise: as.factor. Q2 revise: add error warning. Add comments.  *WH*
#v0.0.3: Q1 revise: add error warning. Q4 revise: rewrite the function.  *WH*
#v0.0.4: *HR*
#########################################
#1
unzip("digits.zip")
unzip("digits.zip", list = T)

read_digits <- function(file_type = NULL) {
    if (file_type != "train" & file_type != "test") {
        stop("no such file name, please input either train or test.")    #if input file_type is wrong, return error.
    }
    rawdata <- read.table(paste(file_type, ".txt", sep = ""))    #paste full file name.
    rawdata[,1] <- as.factor(rawdata[,1])    #convert the labels into factor.
    rawdata
}

#2
train_data <- read_digits("train")
test_data <- read_digits("test")
grays = rgb(red = 0:255/255, blue = 0:255/255, green = 0:255/255)    #define the grayscale color.
view_digit <- function(file_type = NULL, observation_number = NULL) {
    if (file_type != "train" & file_type != "test") {
        stop("no such file name, please input either train or test.")    #if input file_type is wrong, return error.
    }
    if (file_type == "train" & observation_number %in% c(1:7291) == F) {
        stop("exceed the maximum observations, please input an integer between 1 to 7291.")    #if input obs # is wrong, return error.
    } else if (file_type == "test" & observation_number %in% c(1:2007) == F) {
        stop("exceed the maximum observations, please input an integer between 1 to 2007.")
    }
    if (file_type == "train") {
        rawdata <- train_data
    } else if (file_type == "test") {
        rawdata <- test_data
    }
    digit_matrix <- matrix(as.numeric(rawdata[observation_number, 2:257]), 16, 16)    #convert pixel data into matrix.
    digit_matrix <- digit_matrix[,ncol(digit_matrix):1]    #turn the matrix upside down.
    image(digit_matrix, col = grays, axes = F)    #display image.
}

view_digit("train", 1234)    #an example.

#3
par(mfrow = c(2,5))    #align the output images into 2 rows & 5 columns.
for (i in 0:9) {
    digit_data <- train_data[which(train_data$V1 == i),]    #extract data.
    digit_mean <- colMeans(digit_data[, 2:257])    #calculate mean for each pixel points.
    digit_mean <- matrix(as.numeric(digit_mean), 16, 16)    #convert pixel data into matrix.
    digit_mean <- digit_mean[,ncol(digit_mean):1]    #turn the matrix upside down.
    image(digit_mean, col = grays, axes = F)    #display image.
}
#########3.2

#4
predict_knn <- function (test_points = NULL, train_points = NULL, Minkowski_p = 2, k = 3) {
    train_index <- train_points[,1]    #extract label (col1) in training data.
    train_matrix <- as.matrix(train_points[,2:257])    #extract pixel points data in training data.
    real_index <- test_points[,1]    #extract label (col1) in testing data.
    test_matrix <- as.matrix(test_points[,2:257])    #extract pixel points data in testing data.
    train_nrow <- nrow(train_matrix)    #obs # in training data.
    test_nrow <- nrow(test_matrix)    #obs # in testing data.
    predict_result <- matrix(nrow = test_nrow, ncol = 2)    #build empty matrix to record the k nearest distance for each test obs.
    predict_result[,1] <- real_index    #fill col1 with testing real label.
    for (i in 1:test_nrow) {
        test_distance <- abs((matrix(rep(1, times = train_nrow), nrow = train_nrow) %*% t(test_matrix[i,])) - train_matrix)    #absolute difference value between each pixel pairs.
        test_distance <- rowSums(test_distance^Minkowski_p)^(1/Minkowski_p)    #claculate Minkowski Distance.
        test_distance <- cbind(train_index, test_distance)    #link distance with label.
        k_label <- test_distance[order(test_distance[,2])[1:k],1]    #sort and choose the k labels with k nearest distance.
        top_k_label <- sample(names(which(table(k_label) == max(table(k_label)))), 1)    #choose the one with highest prob and sample from the ties.
        predict_result[i,2] <- top_k_label    #fill in the labels.
        colnames(predict_result) <- c("real_digit", "knn")    #change colname: the smallest number after "d" indicate the shortest distance.
    }
    predict_result    #output the table.
}

f <- predict_knn(test_data[1:100,], train_data, 2, 3)    #an example.
# prediction of full test data (2007 obs) takes 52.115 s, will be improve later...

#5
#cv_error_knn <- function()#这里我写完发现了一个问题需要面谈******????????????
index=sample(1:train_nrow, size=train_nrow, replace=FALSE)#随机分组……
nn<-floor(train_nrow/10)#每组个数（最后一组有变化）

#for(i in 1:9)#本来我分了组后来发现其实就直接做就好了所以我就把它注释掉了
#  assign(paste0("fold", i), train_data[index[(nn*(i-1)+1):(nn*i)],])#分组
#fold10<-train_data[index[(nn*9+1):train_nrow],]
ER<-rep(0,10)#error rate
for(i in 1:9){#??????????????????????????????????????????
  pipei<-predict_knn(train_data[index[(nn*(i-1)+1):(nn*i)],], train_data[-index[(nn*(i-1)+1):(nn*i)],], 2, 3)
  ER[i]<-sum(pipei[,1]==pipei[,2])/nn#pipei（匹配）太难听了，换一个
}
#第十组个数不一样，放到循环还要加判断感觉会慢，我就拿出来啦
pipei<-predict_knn(train_data[index[(nn*9+1):train_nrow],], train_data[-index[(nn*9+1):train_nrow],], 2, 3)
ER[10]<-sum(pipei[,1]==pipei[,2])/nn#pipei（匹配）太难听了，换一个
ER
#试运行了一下发现慢的很……大概可以刷个牙
errorrate<-mean(ER)
errorrate

#6
cverror1<-rep(0,15)#10-fold CV error rates for k=1,2,…,15 #1用的是p=1的距离
cverror2<-rep(0,15)#p=2
for(k in 1:15){
  cverror1[k]<-cv_error_knn(k,1)
  cverror2[k]<-cv_error_knn(k,2)
}
plot(cverror1)
points(cverror2)
#结论的哪个最好应该可以直接从图上看？ 后面问有没有用我猜是没用 原因大概是可以根据现有情况看出单调性【理论就是方差偏移分解的那个平衡】

#7
#问题：这里的3个最好的k可以用眼睛看吗，还是要写出来。
#用5里面的pipei #CM是困惑（？）矩阵……
CM<-matrix(0,10,10)
for(l in 1:nn)#as.numeric 应该可以在for外面做更快？
  CM[as.numeric(pipei[l,1]),as.numeric(pipei[l,2])]<-CM[as.numeric(pipei[l,1]),as.numeric(pipei[l,2])]+1
#然后看看困惑矩阵的样子。之前算的是错误率，困惑矩阵应该是研究一下具体的错误是不是足够严重？

#8
#这个题难道不需要代码？

#9
ER1<-rep(0,15)
ER2<-rep(0,15)
for(k in 1:15){
  pipei1<-predict_knn(test_data, train_data, 1, k)
  ER1[k]<-sum(pipei1[,1]==pipei1[,2])/test_nrow
  pipei2<-predict_knn(test_data, train_data, 2, k)
  ER2[k]<-sum(pipei2[,1]==pipei2[,2])/test_nrow
  
}
plot(ER1)
points(ER2)

#10
#这个题肯定不需要代码啦哈哈哈哈哈哈哈哈哈哈
